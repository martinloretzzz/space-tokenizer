{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.token_id = None\n",
    "        self.token = None\n",
    "        self.child_token_count = 0\n",
    "\n",
    "class Trie:\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode()\n",
    "\n",
    "    def insert(self, token, token_id):\n",
    "        node = self.root\n",
    "        for char in token:\n",
    "            if char not in node.children:\n",
    "                node.children[char] = TrieNode()\n",
    "            node = node.children[char]\n",
    "            node.child_token_count += 1\n",
    "        node.token_id = token_id\n",
    "        node.token = token\n",
    "        node.child_token_count += 1\n",
    "\n",
    "    def find_biggest_prefix(self, min_occurence):\n",
    "        prefixes = {}\n",
    "        self.find_biggest_prefix_for_node(self.root, prefixes)\n",
    "        prefixes = {k:v for k, v in prefixes.items() if v > min_occurence}\n",
    "        prefixes = dict(sorted(prefixes.items(), key=lambda item: item[1], reverse=True))\n",
    "        return prefixes\n",
    "\n",
    "    def find_biggest_prefix_for_node(self, node, prefixes):\n",
    "        for child in node.children.values():\n",
    "            prefixes[child.token] = child.child_token_count\n",
    "            self.find_biggest_prefix_for_node(child, prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/vocab.json', 'r', encoding='utf-8') as f: tokenizer_config = json.load(f)\n",
    "\n",
    "suffix = True\n",
    "\n",
    "trie = Trie()\n",
    "for k, v in tokenizer_config.items():\n",
    "    trie.insert(k[::-1] if suffix else k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s': 7297,\n",
       " 'e': 5271,\n",
       " 'd': 4025,\n",
       " 'n': 3856,\n",
       " 't': 3720,\n",
       " 'r': 3038,\n",
       " 'y': 3014,\n",
       " 'g': 2747,\n",
       " 'ed': 2580,\n",
       " 'l': 2377,\n",
       " 'ng': 2282,\n",
       " 'ing': 2129,\n",
       " 'es': 1842,\n",
       " 'er': 1802,\n",
       " 'on': 1709,\n",
       " 'h': 1106,\n",
       " 'ion': 1102,\n",
       " 'a': 1086,\n",
       " 'al': 1085,\n",
       " 'm': 1040,\n",
       " 'nt': 933,\n",
       " 'ly': 898,\n",
       " 'c': 883,\n",
       " 'ts': 881,\n",
       " 'tion': 877,\n",
       " 'rs': 860,\n",
       " 'ns': 794,\n",
       " 'le': 778,\n",
       " 'o': 726,\n",
       " 'k': 710,\n",
       " 'p': 691,\n",
       " 'ted': 639,\n",
       " 'st': 613,\n",
       " 'an': 602,\n",
       " 'ers': 592,\n",
       " 'ent': 585,\n",
       " 're': 550,\n",
       " 'te': 544,\n",
       " 'ce': 519,\n",
       " 'ic': 510,\n",
       " 'ation': 503,\n",
       " 'en': 492,\n",
       " 'i': 489,\n",
       " 'ry': 486,\n",
       " 'ty': 470,\n",
       " 'in': 459,\n",
       " 'ons': 451,\n",
       " 'or': 446,\n",
       " 've': 433,\n",
       " 'ting': 422,\n",
       " 'nd': 419,\n",
       " 'ne': 414,\n",
       " 'us': 393,\n",
       " 'se': 386,\n",
       " 'ss': 380,\n",
       " 'b': 366,\n",
       " 'u': 362,\n",
       " 'ions': 360,\n",
       " 'ter': 354,\n",
       " 'ar': 337,\n",
       " 'll': 328,\n",
       " 'w': 328,\n",
       " 'ies': 327,\n",
       " 'et': 318,\n",
       " 'ge': 312,\n",
       " 'ate': 308,\n",
       " 'ity': 305,\n",
       " 'f': 303,\n",
       " 'ch': 299,\n",
       " 'ble': 298,\n",
       " 'ive': 296,\n",
       " 'nce': 296,\n",
       " 'el': 296,\n",
       " 'ds': 296,\n",
       " 'red': 287,\n",
       " '0': 286,\n",
       " 'ls': 284,\n",
       " 'tions': 283,\n",
       " 'ct': 283,\n",
       " 'th': 274,\n",
       " 'it': 273,\n",
       " 'lly': 271,\n",
       " 'ment': 253,\n",
       " 'S': 251,\n",
       " 'ck': 251,\n",
       " 'ess': 249,\n",
       " 'rd': 239,\n",
       " 'T': 238,\n",
       " 'x': 235,\n",
       " 'E': 233,\n",
       " 'rt': 232,\n",
       " 'v': 232,\n",
       " 'de': 227,\n",
       " 'ated': 217,\n",
       " 'ding': 215,\n",
       " 'ally': 215,\n",
       " 'sh': 206,\n",
       " 'at': 205}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_prefixes = trie.find_biggest_prefix(200)\n",
    "common_prefixes = {(k[::-1] if suffix else k):v for k, v in common_prefixes.items() if len(k) > 0}\n",
    "common_prefixes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
